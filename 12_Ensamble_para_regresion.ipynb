{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0q3RS_bLmSQx"
   },
   "source": [
    "# Ensamble de Regresores\n",
    "1. Preparación de datos\n",
    "2. División de datos\n",
    "3. Predictores individuales\n",
    "4. Bagging\n",
    "5. Random Forest\n",
    "6. Boosting\n",
    "7. Votación \"hard\"\n",
    "8. Votación \"soft\"\n",
    "9. Stacking\n",
    "10. Guardamos el mejor modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "GWePL9N9HSTa"
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4dDdvrfmmsNq"
   },
   "source": [
    "# 1. Preparación de datos"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "OaAd4hOKMQB2",
    "ExecuteTime": {
     "end_time": "2025-09-26T18:48:57.075604Z",
     "start_time": "2025-09-26T18:48:57.055913Z"
    }
   },
   "source": [
    "data = pd.read_excel(\".datos/Emisiones CO2.xlsx\",sheet_name=0)\n",
    "data.info()"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[3]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m data = \u001B[43mpd\u001B[49m.read_excel(\u001B[33m\"\u001B[39m\u001B[33m.datos/Emisiones CO2.xlsx\u001B[39m\u001B[33m\"\u001B[39m,sheet_name=\u001B[32m0\u001B[39m)\n\u001B[32m      2\u001B[39m data.info()\n",
      "\u001B[31mNameError\u001B[39m: name 'pd' is not defined"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "#Correccion de tipo de datos\n",
    "data['Tipo_vehiculo']=data['Tipo_vehiculo'].astype('category')\n",
    "data.info()"
   ],
   "metadata": {
    "id": "EuKzO2I4EqqD"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "laI-LwLqf_iZ",
    "ExecuteTime": {
     "end_time": "2025-09-26T18:48:42.323534Z",
     "start_time": "2025-09-26T18:48:42.248862Z"
    }
   },
   "source": [
    "data['Tipo_vehiculo'].value_counts().plot(kind='bar')"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[43mdata\u001B[49m[\u001B[33m'\u001B[39m\u001B[33mTipo_vehiculo\u001B[39m\u001B[33m'\u001B[39m].value_counts().plot(kind=\u001B[33m'\u001B[39m\u001B[33mbar\u001B[39m\u001B[33m'\u001B[39m)\n",
      "\u001B[31mNameError\u001B[39m: name 'data' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Fw9kNqOxg1gH"
   },
   "source": [
    "data.plot(kind='box')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#Normalizacion las variables numéricas (las dummies no se normalizan)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "min_max_scaler = MinMaxScaler()\n",
    "variables_numericas=['Tamano_motor','Cilindros','Consumo_combustible_ciudad','Consumo_combustible_carretera']\n",
    "min_max_scaler.fit(data[variables_numericas]) #Ajuste de los parametros: max - min\n",
    "data[variables_numericas]= min_max_scaler.transform(data[variables_numericas])\n",
    "data.head()"
   ],
   "metadata": {
    "id": "Nz8oVfWiwQy4"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "LFvKknc0MeY7"
   },
   "source": [
    "#Dummies para las variables predictoras\n",
    "data = pd.get_dummies(data, columns=['Tipo_vehiculo'], drop_first=False)\n",
    "data.head()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **2.División 70-30**"
   ],
   "metadata": {
    "id": "SPJvmWwsx0qQ"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "4CccmWf-Htp-"
   },
   "source": [
    "#División 70-30\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = data.drop(\"CO2_Emision\", axis = 1)\n",
    "Y = data['CO2_Emision']\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3) #En regresion no es muestreo estratificado\n",
    "Y_train.plot(kind='hist')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3KHCB1Vmm0BH"
   },
   "source": [
    "# **3. Predictores individuales (base learners)**"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#Dataframe para comparar los resultados\n",
    "medidas= pd.DataFrame(index=['mse','rmse','mae','mape','max'])"
   ],
   "metadata": {
    "id": "Nw8wihxRFkKW"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7g2XU6IwJrOG"
   },
   "source": [
    "#Arbol de clasificación\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "model_dt = DecisionTreeRegressor(criterion='squared_error', min_samples_leaf=20, max_depth=4)\n",
    "model_dt.fit(X_train, Y_train) # 70%\n",
    "\n",
    "#Evaluación\n",
    "from sklearn import metrics\n",
    "Y_pred = model_dt.predict(X_test)#  30%\n",
    "\n",
    "\n",
    "mse = metrics.mean_squared_error(Y_test,Y_pred) # Entre mas pequeño mejor\n",
    "rmse = np.sqrt(mse) #diferencia entre el valor real y la prediccion\n",
    "mae= metrics.mean_absolute_error(Y_test,Y_pred) #diferencia entre el valor real y la prediccion\n",
    "mape=metrics.mean_absolute_percentage_error(Y_test,Y_pred) # error en porcentaje\n",
    "max=metrics.max_error(Y_test,Y_pred)\n",
    "medidas['Arbol']=[mse, rmse, mae, mape,max]\n",
    "medidas\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.tree import plot_tree\n",
    "plt.figure(figsize=(30,30))\n",
    "plot_tree(model_dt, feature_names=X_train.columns.values,  rounded=True, filled=True)\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "OXO_6kY0kk_-"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model_dt.feature_names_in_"
   ],
   "metadata": {
    "id": "SrL_m61glq3V"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model_dt.feature_importances_\n"
   ],
   "metadata": {
    "id": "oYNyAivwl_Ct"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#Método Perezoso\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "model_knn = KNeighborsRegressor(n_neighbors=1, metric='euclidean') #minkowski\n",
    "model_knn.fit(X_train, Y_train)\n",
    "\n",
    "#Evaluación\n",
    "from sklearn import metrics\n",
    "Y_pred = model_knn.predict(X_test)\n",
    "mse = metrics.mean_squared_error(Y_test,Y_pred) # Entre mas pequeño mejor\n",
    "rmse = np.sqrt(mse) #diferencia entre el valor real y la prediccion\n",
    "mae= metrics.mean_absolute_error(Y_test,Y_pred) #diferencia entre el valor real y la prediccion\n",
    "mape=metrics.mean_absolute_percentage_error(Y_test,Y_pred) # error en porcentaje\n",
    "max=metrics.max_error(Y_test,Y_pred)\n",
    "medidas['Knn']=[mse, rmse, mae, mape,max]\n",
    "medidas\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "6FttuiQ7zAWe"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#Red neuronal\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "model_rn = MLPRegressor(activation=\"logistic\",hidden_layer_sizes=(10), learning_rate='adaptive',\n",
    "                     learning_rate_init=0.2, momentum= 0.3, max_iter=500, verbose=False)\n",
    "model_rn.fit(X_train, Y_train)\n",
    "\n",
    "#Evaluación\n",
    "Y_pred = model_rn.predict(X_test)\n",
    "mse = metrics.mean_squared_error(Y_test,Y_pred) # Entre mas pequeño mejor\n",
    "rmse = np.sqrt(mse) #diferencia entre el valor real y la prediccion\n",
    "mae= metrics.mean_absolute_error(Y_test,Y_pred) #diferencia entre el valor real y la prediccion\n",
    "mape=metrics.mean_absolute_percentage_error(Y_test,Y_pred) # error en porcentaje\n",
    "max=metrics.max_error(Y_test,Y_pred)\n",
    "medidas['NN']=[mse, rmse, mae, mape,max]\n",
    "medidas\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "_WWSipzSzty3"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jd8ORCWInECP"
   },
   "source": [
    "# 4. Bagging"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "tcCGoSwNLHDF"
   },
   "source": [
    "#Bagging: Knn\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "modelo_base=KNeighborsRegressor(n_neighbors=1, metric='euclidean')\n",
    "model_bag = BaggingRegressor(modelo_base, n_estimators=10, max_samples=0.6)\n",
    "model_bag.fit(X_train, Y_train)#70%\n",
    "\n",
    "#Evaluación\n",
    "Y_pred = model_bag.predict(X_test) #30%\n",
    "mse = metrics.mean_squared_error(Y_test,Y_pred) # Entre mas pequeño mejor\n",
    "rmse = np.sqrt(mse) #diferencia entre el valor real y la prediccion\n",
    "mae= metrics.mean_absolute_error(Y_test,Y_pred) #diferencia entre el valor real y la prediccion\n",
    "mape=metrics.mean_absolute_percentage_error(Y_test,Y_pred) # error en porcentaje\n",
    "max=metrics.max_error(Y_test,Y_pred)\n",
    "medidas['Bagging']=[mse, rmse, mae, mape,max]\n",
    "medidas\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OzuLTt_OnInO"
   },
   "source": [
    "# 5. Random Forest (bagging)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "tfD4jTshLLaN"
   },
   "source": [
    "#Random Forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model_rf= RandomForestRegressor(n_estimators=100,  max_samples=0.7, criterion='squared_error',\n",
    "                              max_depth=None, min_samples_leaf=2)\n",
    "model_rf.fit(X_train, Y_train) #70%\n",
    "\n",
    "\n",
    "#Evaluación\n",
    "Y_pred = model_rf.predict(X_test) #30%\n",
    "mse = metrics.mean_squared_error(Y_test,Y_pred) # Entre mas pequeño mejor\n",
    "rmse = np.sqrt(mse) #diferencia entre el valor real y la prediccion\n",
    "mae= metrics.mean_absolute_error(Y_test,Y_pred) #diferencia entre el valor real y la prediccion\n",
    "mape=metrics.mean_absolute_percentage_error(Y_test,Y_pred) # error en porcentaje\n",
    "max=metrics.max_error(Y_test,Y_pred)\n",
    "medidas['Random_Forest']=[mse, rmse, mae, mape,max]\n",
    "medidas\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "UBuTuKXflFud"
   },
   "source": [
    "# Se imprimen la importancia de las características\n",
    "print('Importancia de las características')\n",
    "for i, j in sorted(zip(X_train.columns, model_rf.feature_importances_)):\n",
    "    print(i, j)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_a06D8QroAP9"
   },
   "source": [
    "# 6. Boosting"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "r9CjP8c9Lpc7"
   },
   "source": [
    "#Boosting\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "modelo_base=DecisionTreeRegressor(criterion='squared_error', max_depth=None, min_samples_leaf=2)\n",
    "model_boos = AdaBoostRegressor(modelo_base, n_estimators=50)\n",
    "model_boos.fit(X_train, Y_train)#70%\n",
    "\n",
    "#Evaluación\n",
    "Y_pred = model_boos.predict(X_test)#30%\n",
    "mse = metrics.mean_squared_error(Y_test,Y_pred) # Entre mas pequeño mejor\n",
    "rmse = np.sqrt(mse) #diferencia entre el valor real y la prediccion\n",
    "mae= metrics.mean_absolute_error(Y_test,Y_pred) #diferencia entre el valor real y la prediccion\n",
    "mape=metrics.mean_absolute_percentage_error(Y_test,Y_pred) # error en porcentaje\n",
    "max=metrics.max_error(Y_test,Y_pred)\n",
    "medidas['Boosting']=[mse, rmse, mae, mape,max]\n",
    "medidas"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Librerías y Métodos nuevos de tipo boosting\n",
    "* GradientBoostingRegressor (sklearn)\n",
    "* Librería XGBoost\n",
    "* Librería Catboost (no se crean dummies, trabaja con variables categóricas)"
   ],
   "metadata": {
    "id": "MxietqnkIbIz"
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TzMV6u5UoK2U"
   },
   "source": [
    "# 7. Votación \"hard\""
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "UhlAKS5bL6Pw"
   },
   "source": [
    "#Votación hard\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "regresores= [('dt', model_dt), ('knn', model_knn), ('net', model_rn)]\n",
    "\n",
    "model_vot_hard = VotingRegressor(estimators=regresores, weights=None)\n",
    "model_vot_hard.fit(X_train,Y_train) #70%\n",
    "\n",
    "#Evaluación\n",
    "Y_pred = model_vot_hard.predict(X_test)#30%\n",
    "mse = metrics.mean_squared_error(Y_test,Y_pred) # Entre mas pequeño mejor\n",
    "rmse = np.sqrt(mse) #diferencia entre el valor real y la prediccion\n",
    "mae= metrics.mean_absolute_error(Y_test,Y_pred) #diferencia entre el valor real y la prediccion\n",
    "mape=metrics.mean_absolute_percentage_error(Y_test,Y_pred) # error en porcentaje\n",
    "max=metrics.max_error(Y_test,Y_pred)\n",
    "medidas['Votacion_hard']=[mse, rmse, mae, mape,max]\n",
    "medidas\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VDxuUT3yoSxA"
   },
   "source": [
    "# 8. Votación \"soft\""
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "x2oiZ6CiMFDs"
   },
   "source": [
    "#Votación soft\n",
    "\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "regresores= [('dt', model_dt), ('knn', model_knn), ('net', model_rn)]\n",
    "model_vot_soft = VotingRegressor(estimators=regresores, weights=[0.3, 0.4, 0.3])\n",
    "model_vot_soft.fit(X_train,Y_train) #70%\n",
    "\n",
    "#Evaluación\n",
    "Y_pred = model_vot_soft.predict(X_test) #30%\n",
    "mse = metrics.mean_squared_error(Y_test,Y_pred) # Entre mas pequeño mejor\n",
    "rmse = np.sqrt(mse) #diferencia entre el valor real y la prediccion\n",
    "mae= metrics.mean_absolute_error(Y_test,Y_pred) #diferencia entre el valor real y la prediccion\n",
    "mape=metrics.mean_absolute_percentage_error(Y_test,Y_pred) # error en porcentaje\n",
    "max=metrics.max_error(Y_test,Y_pred)\n",
    "medidas['Votacion_soft']=[mse, rmse, mae, mape,max]\n",
    "medidas\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MjV03LKYXAC7"
   },
   "source": [
    "# 9. Stacking"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "XDthgeKJWkGK"
   },
   "source": [
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "regresores= [('dt', model_dt), ('knn', model_knn), ('net', model_rn)]\n",
    "\n",
    "metodo_ensamblador= LinearRegression()\n",
    "\n",
    "#metodo_ensamblador = SVR(kernel='linear', probability=True) #'linear', 'poly', 'rbf', 'sigmoid', 'precomputed'\n",
    "\n",
    "model_stack= StackingRegressor(estimators=regresores, final_estimator=metodo_ensamblador)\n",
    "model_stack.fit(X_train,Y_train)#70%\n",
    "\n",
    "#Evaluación\n",
    "Y_pred = model_stack.predict(X_test) #30%\n",
    "mse = metrics.mean_squared_error(Y_test,Y_pred) # Entre mas pequeño mejor\n",
    "rmse = np.sqrt(mse) #diferencia entre el valor real y la prediccion\n",
    "mae= metrics.mean_absolute_error(Y_test,Y_pred) #diferencia entre el valor real y la prediccion\n",
    "mape=metrics.mean_absolute_percentage_error(Y_test,Y_pred) # error en porcentaje\n",
    "max=metrics.max_error(Y_test,Y_pred)\n",
    "medidas['Stacking']=[mse, rmse, mae, mape,max]\n",
    "medidas\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **10. Guardamos el mejor modelo**"
   ],
   "metadata": {
    "id": "ZsipEsA73gRH"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "filename = 'modelo-ensamble-reg.pkl'\n",
    "variables=X.columns._values\n",
    "pickle.dump([model_boos,variables, min_max_scaler], open(filename, 'wb'))\n",
    "\n"
   ],
   "metadata": {
    "id": "nFGEMnsZ3m8Q"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
